"""
LLM æ¨¡å‹å®¢æˆ·ç«¯ç®¡ç†æ¨¡å—
æä¾›å„ç§ LLM æ¨¡å‹å®¢æˆ·ç«¯çš„åˆ›å»ºå’Œç®¡ç†åŠŸèƒ½
æ”¯æŒ UI è‡ªåŠ¨åŒ–ã€å›¾åƒåˆ†æç­‰å¤šç§åœºæ™¯
"""
from typing import Optional
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import ModelInfo
from .config import Settings



# å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜
_uitars_model_client: Optional[OpenAIChatCompletionClient] = None
_deepseek_client_cache: Optional[OpenAIChatCompletionClient] = None
_default_model_client: Optional[OpenAIChatCompletionClient] = None


def _get_uitars_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å– UI-TARS æ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äº UI è‡ªåŠ¨åŒ–å’Œå›¾åƒåˆ†æ

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _uitars_model_client

    if _uitars_model_client is None:
        if settings is None:
            from .config import settings as global_settings
            settings = global_settings

        # ä»é…ç½®ä¸­è·å– UI-TARS æ¨¡å‹ä¿¡æ¯
        uitars_model = getattr(settings, 'uitars_model', 'gpt-4o')
        uitars_api_key = getattr(settings, 'uitars_api_key', settings.api_key)
        uitars_base_url = getattr(settings, 'uitars_base_url', settings.base_url)

        # è°ƒè¯•ä¿¡æ¯
        print(f"\nğŸ” UI-TARS æ¨¡å‹é…ç½®:")
        print(f"   æ¨¡å‹: {uitars_model}")
        print(f"   API Key: {uitars_api_key[:20]}...{uitars_api_key[-10:] if uitars_api_key and len(uitars_api_key) > 30 else uitars_api_key}")
        print(f"   Base URL: {uitars_base_url}")

        _uitars_model_client = OpenAIChatCompletionClient(
            model=uitars_model,
            api_key=uitars_api_key,
            base_url=uitars_base_url,
            model_info={
                "vision": True,
                "function_calling": True,
                "json_output": True,
                "structured_output": True,
                "family": "unknown",
                "multiple_system_messages": True,
            },
        )
        print(f"âœ… UI-TARS æ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»ºæˆåŠŸ")

    return _uitars_model_client


def _deepseek_model_client(settings: Optional[Settings] = None) -> OpenAIChatCompletionClient:
    """
    è·å–deepseekæ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äºé€šç”¨å¯¹è¯å’Œæ–‡æœ¬å¤„ç†

    å‚æ•°:
        settings: é…ç½®å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å…¨å±€é…ç½®

    è¿”å›:
        OpenAIChatCompletionClient å®ä¾‹
    """
    global _deepseek_client_cache

    if _deepseek_client_cache is None:
        if settings is None:
            from .config import settings as global_settings
            settings = global_settings

        _deepseek_client_cache = OpenAIChatCompletionClient(
            model=settings.MODEL_NAME,
            api_key=settings.API_KEY,
            base_url=settings.BASE_URL,
            model_info={
                "vision": False,
                "function_calling": True,
                "json_output": True,
                "structured_output": True,
                "family": _get_model_family(settings.MODEL_NAME),
                "multiple_system_messages": True,
            },
            # å¯ç”¨æµå¼è¾“å‡ºé€‰é¡¹
            stream_options={"include_usage": True},
        )
        print(f"âœ… DeepSeekæ¨¡å‹å®¢æˆ·ç«¯å·²åˆ›å»º: {settings.MODEL_NAME}")

    return _deepseek_client_cache


def _get_model_family(model_name: Optional[str]) -> str:
    """
    æ ¹æ®æ¨¡å‹åç§°æ¨æ–­æ¨¡å‹å®¶æ—

    å‚æ•°:
        model_name: æ¨¡å‹åç§°ï¼Œå¯ä»¥ä¸º None

    è¿”å›:
        æ¨¡å‹å®¶æ—åç§°
    """
    if model_name is None:
        return "unknown"

    model_name_lower = model_name.lower()

    if "deepseek" in model_name_lower:
        return "deepseek"
    elif "gpt" in model_name_lower or "openai" in model_name_lower:
        return "openai"
    elif "claude" in model_name_lower:
        return "anthropic"
    elif "gemini" in model_name_lower:
        return "google"
    elif "qwen" in model_name_lower:
        return "qwen"
    elif "doubao" in model_name_lower or "ui-tars" in model_name_lower:
        return "doubao"
    else:
        return "unknown"


def reset_model_clients() -> None:
    """
    é‡ç½®æ‰€æœ‰æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜
    ç”¨äºé…ç½®æ›´æ–°åé‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
    """
    global _uitars_model_client, _deepseek_client_cache, _default_model_client

    _uitars_model_client = None
    _deepseek_client_cache = None
    _default_model_client = None

    print("ğŸ”„ æ‰€æœ‰æ¨¡å‹å®¢æˆ·ç«¯ç¼“å­˜å·²é‡ç½®")

